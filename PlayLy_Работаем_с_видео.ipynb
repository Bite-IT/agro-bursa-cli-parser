{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PlayLy Работаем с видео.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1kSo_6BH_Fx7wTO-EBhOWVtzr6kyWH1V2",
      "authorship_tag": "ABX9TyNMqZXkyv6uMjlV/fWfdvNV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bite-IT/agro-bursa-cli-parser/blob/main/PlayLy_%D0%A0%D0%B0%D0%B1%D0%BE%D1%82%D0%B0%D0%B5%D0%BC_%D1%81_%D0%B2%D0%B8%D0%B4%D0%B5%D0%BE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wr9xfPkHsr4"
      },
      "source": [
        "#Повышаем качество распознавания OpenPose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KICxb8ZBHZjV"
      },
      "source": [
        "#@title ##**Устанавливаем необходимые библиотеки** { display-mode: \"form\" }\n",
        "!pip install youtube_dl\n",
        "!pip install ffmpeg\n",
        "!pip install ffmpeg-python\n",
        "!pip install torchvision==0.5\n",
        "!pip install torch==1.4\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "import imageio\n",
        "import youtube_dl\n",
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import fastai\n",
        "import ffmpeg\n",
        "import os.path as osp\n",
        "import logging\n",
        "import shutil\n",
        "import re\n",
        "import gc\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from os import path\n",
        "import numpy as np\n",
        "import moviepy.editor as mpy\n",
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import glob\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import Image as ipythonimage\n",
        "torch.backends.cudnn.benchmark=True\n",
        "%matplotlib inline\n",
        "\n",
        "!rm -rf sample_data\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGCaOjWtIByx"
      },
      "source": [
        "#@title ###*Скачиваем видео* { display-mode: \"form\" }\n",
        "#@markdown *Вставьте ссылку на видео (YouTube or Twitter), или оставьте поле **source_url** пустым и загрузите файл с компьютера.*\n",
        "source_url = 'https://www.youtube.com/watch?v=DeQwRF6FKQo' #@param {type:\"string\"}\n",
        "\n",
        "if source_url == '':\n",
        "  uploaded = files.upload()\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "  os.rename(fn, fn.replace(\" \", \"\"))\n",
        "  fn = fn.replace(\" \", \"\")\n",
        "  file_name = \"downloaded_video.\" + fn.split(\".\")[-1]\n",
        "  !mv -f $fn $file_name\n",
        "\n",
        "else:\n",
        "  try:\n",
        "    ydl_opts = {\n",
        "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4',\n",
        "        'outtmpl': 'downloaded_video.mp4',\n",
        "        }\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "      ydl.download([source_url])\n",
        "    file_name = 'downloaded_video.mp4'\n",
        "  \n",
        "  except BaseException:\n",
        "    !wget $source_url\n",
        "    fn = source_url.split('/')[-1]\n",
        "    os.rename(fn, fn.replace(\" \", \"\"))\n",
        "    fn = fn.replace(\" \", \"\")\n",
        "    file_name = \"downloaded_video.\" + fn.split(\".\")[-1]\n",
        "    !mv -f $fn $file_name\n",
        "\n",
        "!cp -r downloaded_video.mp4 video.mp4\n",
        "clear_output()\n",
        "fps_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FPS))\n",
        "frames_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "#@markdown *НЕ рекомендуется загружать длинные видео.*\n",
        "\n",
        "#@markdown *Если будут ошибки - перезапустите клетку*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoJosoxTbqNJ"
      },
      "source": [
        "#@title ###*Обрезаем видео* { display-mode: \"form\" }\n",
        "\n",
        "#@markdown **Enter the time frame for croping the video**\n",
        "target_start = '00:5:00' #@param {type:\"string\"}\n",
        "target_end = '00:5:03' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter a new resolution of the video file for rescaling (*for example, 640 and 480*), or leave it blank to work with the original resolution\n",
        "width = '' #@param {type:\"string\"}\n",
        "height = '' #@param {type:\"string\"}\n",
        "\n",
        "rescale = \"\"\n",
        "if width != '' and height != '':\n",
        "  rescale = f\"-s {width}x{height}\"\n",
        "\n",
        "!ffmpeg -i downloaded_video.mp4 $rescale -ss $target_start -to $target_end new_target.mp4\n",
        "clear_output()\n",
        "!rm video.mp4\n",
        "!mv new_target.mp4 video.mp4\n",
        "#@markdown *Display video:*\n",
        "display_video = False #@param {type:\"boolean\"}\n",
        "if display_video == True:\n",
        "  display(mpy.ipython_display(\"video.mp4\", height=400))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETPwFp1Ld29P"
      },
      "source": [
        "#@title ##**Улучшаем качество видео с EDVR** { display-mode: \"form\" }\n",
        "%cd /content\n",
        "!pip install numpy opencv-python lmdb pyyaml\n",
        "!pip install tb-nightly future\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTPYjXvffBui"
      },
      "source": [
        "#@title ###*Создаем папки и скачиваем модель* { display-mode: \"form\" }\n",
        "!git clone -b old_version https://github.com/xinntao/EDVR\n",
        "%cd /content/EDVR/\n",
        "!mkdir  experiments\n",
        "%cd /content/EDVR/experiments\n",
        "!mkdir  pretrained_models\n",
        "%cd /content/EDVR/codes/models/archs/dcn\n",
        "!python setup.py develop\n",
        "%cd /content/EDVR/codes\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1SGVehpZt4WL_X8Jh6blyqmHpc8DdImgv' -O /content/EDVR/experiments/pretrained_models/EDVR_REDS_deblurcomp_L.pth\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdFYGJq6ZFxr"
      },
      "source": [
        "#@title ###*Инициализируем функции* { display-mode: \"form\" }\n",
        "import utils.util as util\n",
        "import data.util as data_util\n",
        "import models.archs.EDVR_arch as EDVR_arch\n",
        "\n",
        "workfolder = Path('./video')\n",
        "source_folder = workfolder / \"source\"\n",
        "inframes_root = workfolder / \"inframes\"\n",
        "audio_root = workfolder / \"audio\"\n",
        "outframes_root = workfolder / \"outframes\"\n",
        "result_folder = workfolder / \"result\"\n",
        "pretrained_models = Path('../experiments/pretrained_models')\n",
        "\n",
        "def clean_mem():\n",
        "    # torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "def get_fps(source_path: Path) -> str:\n",
        "    print(source_path)\n",
        "    probe = ffmpeg.probe(str(source_path))\n",
        "    stream_data = next(\n",
        "        (stream for stream in probe['streams'] if stream['codec_type'] == 'video'),\n",
        "        None,\n",
        "    )\n",
        "    return stream_data['avg_frame_rate']\n",
        "\n",
        "def preProcess(imag_path_l, multiple):\n",
        "  '''Need to resize images for blurred model (needs to be multiples of 16)'''\n",
        "  for img_path in imag_path_l:\n",
        "    im = Image.open(img_path)\n",
        "    h, w = im.size\n",
        "    # resize so they are multiples of 4 or 16 (for blurred)\n",
        "    h = h - h % multiple\n",
        "    w = w - w % multiple\n",
        "    im = im.resize((h,w))\n",
        "    im.save(img_path)\n",
        "\n",
        "def purge_images(dir):\n",
        "  for f in os.listdir(dir):\n",
        "    if re.search('.*?\\.jpg', f):\n",
        "      os.remove(os.path.join(dir, f))\n",
        "\n",
        "def extract_raw_frames(source_path: Path):\n",
        "    inframes_folder = inframes_root / (source_path.stem)\n",
        "    inframe_path_template = str(inframes_folder / '%5d.jpg')\n",
        "    inframes_folder.mkdir(parents=True, exist_ok=True)\n",
        "    purge_images(inframes_folder)\n",
        "    ffmpeg.input(str(source_path)).output(\n",
        "        str(inframe_path_template), format='image2', vcodec='mjpeg', qscale=0\n",
        "    ).run(capture_stdout=True)\n",
        "\n",
        "def make_subfolders(img_path_l, chunk_size):\n",
        "  i = 0\n",
        "  subFolderList = []\n",
        "  source_img_path = Path('/content/EDVR/codes/video/inframes/video_subfolders')\n",
        "  source_img_path.mkdir(parents=True, exist_ok=True)\n",
        "  for img in img_path_l:\n",
        "    if i % chunk_size == 0:\n",
        "      img_path = source_img_path / str(i)\n",
        "      img_path.mkdir(parents=True, exist_ok=True)\n",
        "      subFolderList.append(str(img_path))\n",
        "    i+=1\n",
        "    img_name = osp.basename(img)\n",
        "    img_path_name = img_path / img_name\n",
        "    shutil.copyfile(img, img_path_name)\n",
        "\n",
        "  return subFolderList\n",
        "\n",
        "def remove_subfolders():\n",
        "  shutil.rmtree('/content/EDVR/codes/video/inframes/video_subfolders', ignore_errors=True, onerror=None)\n",
        "\n",
        "def edvrPredict(data_mode, chunk_size, stage):\n",
        "  device = torch.device('cuda')\n",
        "  os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "  data_mode = \"blur_comp\"\n",
        "  stage = stage  # 1 or 2, use two stage strategy for REDS dataset.\n",
        "  flip_test = False\n",
        "  model_path = pretrained_models / 'EDVR_REDS_deblurcomp_L.pth'   \n",
        "\n",
        "  print('Model Used: ', model_path)\n",
        "  \n",
        "  if data_mode == 'Vid4':\n",
        "      N_in = 7  # use N_in images to restore one HR image\n",
        "  else:\n",
        "      N_in = 5\n",
        "\n",
        "  predeblur, HR_in = False, False\n",
        "  back_RBs = 40\n",
        "  if data_mode == 'blur' or data_mode == 'blur_comp':\n",
        "      predeblur, HR_in = True, True\n",
        "  if stage == 2:\n",
        "      HR_in = True\n",
        "      back_RBs = 20\n",
        "  if data_mode == 'TOF':\n",
        "    model = TOF_arch.TOFlow(adapt_official=True)\n",
        "  else:\n",
        "    model = EDVR_arch.EDVR(128, N_in, 8, 5, back_RBs, predeblur=predeblur, HR_in=HR_in)\n",
        "\n",
        "  #### dataset\n",
        "  test_dataset_folder = '/content/EDVR/codes/video/inframes'\n",
        "\n",
        "  #### evaluation\n",
        "  crop_border = 0\n",
        "  border_frame = N_in // 2  # border frames when evaluate\n",
        "  # temporal padding mode\n",
        "  if data_mode in ('Vid4','sharp_bicubic'):\n",
        "      padding = 'new_info'\n",
        "  else:\n",
        "      padding = 'replicate'\n",
        "  save_imgs = True\n",
        "\n",
        "  save_folder = '/content/EDVR/codes/video/outframes'\n",
        "  util.mkdirs(save_folder)\n",
        "\n",
        "  #### set up the models\n",
        "  model.load_state_dict(torch.load(model_path), strict=True)\n",
        "  model.eval()\n",
        "  model = model.to(device)\n",
        "\n",
        "  avg_psnr_l, avg_psnr_center_l, avg_psnr_border_l = [], [], []\n",
        "  subfolder_name_l = []\n",
        "  # remove old video_subfolder if exists\n",
        "  remove_subfolders()\n",
        "  subfolder_l = sorted(glob.glob(osp.join(test_dataset_folder, '*')))\n",
        "\n",
        "  # for each subfolder\n",
        "  for subfolder in subfolder_l:\n",
        "      subfolder_name = osp.basename(subfolder)\n",
        "      subfolder_name_l.append(subfolder_name)\n",
        "      save_subfolder = osp.join(save_folder, subfolder_name)\n",
        "\n",
        "      img_path_l = sorted(glob.glob(osp.join(subfolder, '*')))\n",
        "      if save_imgs:\n",
        "          util.mkdirs(save_subfolder)\n",
        "          purge_images(save_subfolder)\n",
        "\n",
        "      # preprocess images (needed for blurred models)\n",
        "      if predeblur:\n",
        "        preProcess(img_path_l, 16)\n",
        "      else:\n",
        "        preProcess(img_path_l, 4)\n",
        "      # make even more subfolders\n",
        "      subFolderList = make_subfolders(img_path_l, chunk_size)\n",
        "\n",
        "      #### read LQ and GT images in chunks of 1000\n",
        "      for subSubFolder in subFolderList:\n",
        "        clean_mem()\n",
        "        imgs_LQ = data_util.read_img_seq(subSubFolder)\n",
        "        subSubFolder_l = sorted(glob.glob(osp.join(subSubFolder, '*')))\n",
        "        max_idx = len(subSubFolder_l)\n",
        "        avg_psnr, avg_psnr_border, avg_psnr_center, N_border, N_center = 0, 0, 0, 0, 0\n",
        "\n",
        "        # process each image\n",
        "        for img_idx, img_path in tqdm(enumerate(subSubFolder_l)):\n",
        "            img_name = osp.splitext(osp.basename(img_path))[0]\n",
        "            select_idx = data_util.index_generation(img_idx, max_idx, N_in, padding=padding)\n",
        "            imgs_in = imgs_LQ.index_select(0, torch.LongTensor(select_idx)).unsqueeze(0).to(device)\n",
        "\n",
        "            if flip_test:\n",
        "                output = util.flipx4_forward(model, imgs_in)\n",
        "            else:\n",
        "                output = util.single_forward(model, imgs_in)\n",
        "            output = util.tensor2img(output.squeeze(0))\n",
        "\n",
        "            if save_imgs:\n",
        "                cv2.imwrite(osp.join(save_subfolder, '{}.jpg'.format(img_name)), output)\n",
        "                # print('Saved Image:', str(osp.join(save_subfolder, '{}.jpg'.format(img_name))))\n",
        "\n",
        "def moveProcessedFrames():\n",
        "  shutil.rmtree('/content/EDVR/codes/video/inframes')\n",
        "  os.rename('/content/EDVR/codes/video/outframes', '/content/EDVR/codes/video/inframes')\n",
        "\n",
        "def build_video(source_path: Path) -> Path:\n",
        "        out_path = result_folder / (\n",
        "            source_path.name.replace('.mp4', '_no_audio.mp4')\n",
        "        )\n",
        "        outframes_folder = outframes_root / (source_path.stem)\n",
        "        outframes_path_template = str(outframes_folder / '%5d.jpg')\n",
        "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        if out_path.exists():\n",
        "            out_path.unlink()\n",
        "        fps = get_fps(source_path)\n",
        "        print('Original FPS is: ', fps)\n",
        "\n",
        "        ffmpeg.input(\n",
        "            str(outframes_path_template),\n",
        "            format='image2',\n",
        "            vcodec='mjpeg',\n",
        "            framerate=fps,\n",
        "        ).output(str(out_path), crf=17, vcodec='libx264').run(capture_stdout=True)\n",
        "\n",
        "        result_path = result_folder / source_path.name\n",
        "        if result_path.exists():\n",
        "            result_path.unlink()\n",
        "        # making copy of non-audio version in case adding back audio doesn't apply or fails.\n",
        "        shutil.copyfile(str(out_path), str(result_path))\n",
        "\n",
        "        # adding back sound here\n",
        "        audio_file = Path(str(source_path).replace('.mp4', '.aac'))\n",
        "        if audio_file.exists():\n",
        "            audio_file.unlink()\n",
        "\n",
        "        os.system(\n",
        "            'ffmpeg -y -i \"'\n",
        "            + str(source_path)\n",
        "            + '\" -vn -acodec copy \"'\n",
        "            + str(audio_file)\n",
        "            + '\"'\n",
        "        )\n",
        "\n",
        "        if audio_file.exists:\n",
        "            os.system(\n",
        "                'ffmpeg -y -i \"'\n",
        "                + str(out_path)\n",
        "                + '\" -i \"'\n",
        "                + str(audio_file)\n",
        "                + '\" -shortest -c:v copy -c:a aac -b:a 256k \"'\n",
        "                + str(result_path)\n",
        "                + '\"'\n",
        "            )\n",
        "        print('Video created here: ' + str(result_path))\n",
        "        return result_path\n",
        "\n",
        "def edvr_video(source_path: Path, chunk_size: int):\n",
        "    # extract frames\n",
        "    extract_raw_frames(source_path)\n",
        "\n",
        "    # process frames\n",
        "    edvrPredict(\"blur_comp\", chunk_size, 1)\n",
        "\n",
        "    # build back video\n",
        "    build_video(source_path)\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnuyrT8KkH8d"
      },
      "source": [
        "#@title ###*Увеличиваем качество кадров* { display-mode: \"form\" }\n",
        "%%time\n",
        "edvr_video(Path('/content/video.mp4'), 100)\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyX_tlwzkQYG"
      },
      "source": [
        "#@title ###*Результат* { display-mode: \"form\" }\n",
        "!rm -rf /content/video.mp4\n",
        "!cp -r /content/EDVR/codes/video/result/video.mp4 /content/video.mp4\n",
        "!cp -r /content/EDVR/codes/video/result/video.mp4 /content/enhanced_video.mp4\n",
        "what_next = 'download' #@param [\"play\", \"download\"]\n",
        "if what_next == \"play\":\n",
        "  display(mpy.ipython_display(\"/content/enhanced_video.mp4\", height=400, autoplay=1, loop=1, maxduration=600))\n",
        "else:\n",
        "  files.download('/content/enhanced_video.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9TGOvXIkoba"
      },
      "source": [
        "#@title ##**Определяем позы с OpenPose** { display-mode: \"form\" }\n",
        "%cd /content\n",
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/CMU-Perceptual-Computing-Lab/openpose.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # see: https://github.com/CMU-Perceptual-Computing-Lab/openpose/issues/949\n",
        "  # install new CMake becaue of CUDA10\n",
        "  !wget -q https://cmake.org/files/v3.13/cmake-3.13.0-Linux-x86_64.tar.gz\n",
        "  !tar xfz cmake-3.13.0-Linux-x86_64.tar.gz --strip-components=1 -C /usr/local\n",
        "  # clone openpose\n",
        "  !git clone -q --depth 1 $git_repo_url\n",
        "  !sed -i 's/execute_process(COMMAND git checkout master WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/execute_process(COMMAND git checkout f019d0dfe86f49d1140961f8c7dec22130c83154 WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/g' openpose/CMakeLists.txt\n",
        "  # install system dependencies\n",
        "  !apt-get -qq install -y libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler libgflags-dev libgoogle-glog-dev liblmdb-dev opencl-headers ocl-icd-opencl-dev libviennacl-dev\n",
        "  # install python dependencies\n",
        "  !pip install -q youtube-dl\n",
        "  # build openpose\n",
        "  !cd openpose && rm -rf build || true && mkdir build && cd build && cmake .. && make -j`nproc`\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3nCTrrxvHeK"
      },
      "source": [
        "#@title ###*Детектируем позы футболистов на улучшенном видео* { display-mode: \"form\" }\n",
        "!rm openpose.avi\n",
        "!cd openpose && ./build/examples/openpose/openpose.bin --video /content/enhanced_video.mp4 --write_json ./output/ --display 0  --write_video ../openpose.avi\n",
        "# convert the result into MP4\n",
        "!ffmpeg -y -loglevel info -i openpose.avi output.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGb1SzdavmA0"
      },
      "source": [
        "#@title ###*Детектируем позы футболистов на исходном  видео* { display-mode: \"form\" }\n",
        "!rm openpose.avi\n",
        "!cd openpose && ./build/examples/openpose/openpose.bin --video /content/video.mp4 --write_json ./output/ --display 0  --write_video ../openpose.avi\n",
        "# convert the result into MP4\n",
        "!ffmpeg -y -loglevel info -i openpose.avi output2.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty6AuFaTAJoG"
      },
      "source": [
        "---\n",
        "# <b>Увеличиваем разрешение видео"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4FTrPsmNVYG"
      },
      "source": [
        "#@title ##**Используем Video2X**{ display-mode: \"form\" }\n",
        "!apt install ffmpeg\n",
        "!apt install libmagic1 python3-yaml\n",
        "!apt install libvulkan-dev\n",
        "!pip install --user youtube-dl  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5AN7cMKNaYY"
      },
      "source": [
        "#@title ###*Загружаем репозиторий Video2X c GitHub*{ display-mode: \"form\" }\n",
        "!git clone https://github.com/k4yt3x/video2x.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ-26fWvNete"
      },
      "source": [
        "#@title ###*Устанавливаем*{ display-mode: \"form\" }\n",
        "import os\n",
        "os.chdir('video2x/src')\n",
        "!git checkout 4.7.0\n",
        "!pip install -r requirements.txt\n",
        "!rm -rf video2x.yaml\n",
        "!wget -O video2x.yaml http://akas.io/v2xcolab\n",
        "os.chdir('../..')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul5uXPFxNhrT"
      },
      "source": [
        "#@title ###*Скачиваем модели*{ display-mode: \"form\" }\n",
        "!wget https://github.com/nihui/realsr-ncnn-vulkan/releases/download/20200818/realsr-ncnn-vulkan-20200818-linux.zip\n",
        "!7z x realsr-ncnn-vulkan-20200818-linux.zip\n",
        "!wget https://github.com/nihui/waifu2x-ncnn-vulkan/releases/download/20200818/waifu2x-ncnn-vulkan-20200818-linux.zip\n",
        "!7z x waifu2x-ncnn-vulkan-20200818-linux.zip\n",
        "!wget https://github.com/nihui/srmd-ncnn-vulkan/releases/download/20200818/srmd-ncnn-vulkan-20200818-linux.zip\n",
        "!7z x srmd-ncnn-vulkan-20200818-linux.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE4sj-EmNkgJ"
      },
      "source": [
        "#@title ###*Запускаем обработку для video.mp4  (может занять > 10 часов)*{ display-mode: \"form\" }\n",
        "!pip install -U PyYAML\n",
        "!python video2x/src/video2x.py -i /content/video.mp4 -o video_4x.mp4 -d waifu2x_ncnn_vulkan -r 4.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9dUA0cjJn5G"
      },
      "source": [
        "#@title ###*Скачиваем результат на диск*{ display-mode: \"form\" }\n",
        "!cp video_4x.mp4 \"/content/drive/MyDrive/video_4x_2.mp4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2USmtGjCQMtc"
      },
      "source": [
        "#@title ##**Используем ESRGAN**{ display-mode: \"form\" }\n",
        "%cd /content\n",
        "!git clone https://github.com/xinntao/ESRGAN\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSrAlvPHvh5W"
      },
      "source": [
        "#@title ###*Загружаем и устанавливаем репозиторий*{ display-mode: \"form\" }\n",
        "\n",
        "!cp -r /content/video.mp4 /content/ESRGAN/\n",
        "%cd /content/ESRGAN\n",
        "!git checkout tags/old-arch\n",
        "model_url = \"https://www.dropbox.com/s/vouc15j8jjp2o5n/RRDB_ESRGAN_x4_old_arch.pth?dl=0\"\n",
        "!wget $model_url --content-disposition -P models\n",
        "import architecture as arch\n",
        "import os.path\n",
        "!mkdir frames\n",
        "!rm -rf results/baboon_ESRGAN.png\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoC7elpSBHBl"
      },
      "source": [
        "#@title ###*Делим видео на кадры* { display-mode: \"form\" }\n",
        "frames_of_video = int(cv2.VideoCapture(\"video.mp4\").get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "fps_of_video = int(cv2.VideoCapture(\"video.mp4\").get(cv2.CAP_PROP_FPS))\n",
        "vidcap = cv2.VideoCapture('video.mp4')\n",
        "success,image = vidcap.read()\n",
        "count = 0\n",
        "success = True\n",
        "while success:\n",
        "  cv2.imwrite(\"frames/frame%09d.jpg\" % count, image)\n",
        "  success,image = vidcap.read()\n",
        "  count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC7HRJzu2LI1"
      },
      "source": [
        "#@title ###*Проверяем состояние GPU*{ display-mode: \"form\" }\n",
        "import torch\n",
        "\n",
        "# setting device on GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "#Additional Info when using cuda\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPvEQSN254Ip"
      },
      "source": [
        "#@title ###*Устанавливаем утилиты для работы с GPU*{ display-mode: \"form\" }\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba8x0J5zCIwv"
      },
      "source": [
        "#@title ###*Повышаем разрешение каждого кадра* { display-mode: \"form\" }\n",
        "import architecture as arch\n",
        "import os.path\n",
        "upscale = 4 \n",
        "%env CUDA_VISIBLE_DEVICES=0\n",
        "device = torch.device('cuda')\n",
        "model = arch.RRDB_Net(3, 3, 64, 23, gc=32, upscale=upscale, norm_type=None, act_type='leakyrelu', \\\n",
        "                        mode='CNA', res_scale=1, upsample_mode='upconv')\n",
        "model.load_state_dict(torch.load('models/{:s}'.format('RRDB_ESRGAN_x4_old_arch.pth')), strict=True)\n",
        "model.eval()\n",
        "for k, v in model.named_parameters():\n",
        "    v.requires_grad = False\n",
        "model = model.to(device)\n",
        "\n",
        "count_frames = 0\n",
        "\n",
        "for path in glob.glob('frames/*'):\n",
        "    base = os.path.splitext(os.path.basename(path))[0]\n",
        "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    img = img * 1.0 / 255\n",
        "    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n",
        "    img_LR = img.unsqueeze(0)\n",
        "    img_LR = img_LR.to(device)\n",
        "\n",
        "    output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
        "    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n",
        "    output = (output * 255.0).round()\n",
        "    path = 'results/{:s}_rlt.png'.format(base)\n",
        "    cv2.imwrite(path, output)\n",
        "    count_frames += 1\n",
        "    \n",
        "    print(\"Processed: {} из {}\".format(str(count_frames), str(frames_of_video)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNa68e5DCZnn"
      },
      "source": [
        "#@title ###*Собираем видео из кадров* { display-mode: \"form\" }\n",
        "frames = []\n",
        "img = os.listdir(\"results/\")\n",
        "img.sort()\n",
        "for i in img:\n",
        "  frames.append(imageio.imread(\"results/\"+i))\n",
        "frames = np.array(frames)\n",
        "imageio.mimsave(\"upscaled_video.mp4\", frames, fps=fps_of_video)\n",
        "\n",
        "print('Сборка завершена')\n",
        "!cp -r upscaled_video.mp4 /content/upscaled_video.mp4\n",
        "!cp -r upscaled_video.mp4 /content/video.mp4\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkw6jOEyCkkv"
      },
      "source": [
        "#@title ###*Получаем результат* { display-mode: \"form\" }\n",
        "what_next = 'play' #@param [\"play\", \"download\"]\n",
        "if what_next == \"play\":\n",
        "  display(mpy.ipython_display(\"/content/upscaled_video.mp4\", height=400, autoplay=1, loop=1, maxduration=600))\n",
        "else:\n",
        "  files.download(\"/content/upscaled_video.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDkiN5N9lFVR"
      },
      "source": [
        "#@title ###*Детектируем позы футболистов на видео с увеличенным разрешением Video2X* { display-mode: \"form\" }\n",
        "!rm openpose.avi\n",
        "!cd openpose && ./build/examples/openpose/openpose.bin --video /content/drive/MyDrive/video_4x_2.mp4 --write_json ./output/ --display 0  --write_video ../openpose.avi\n",
        "# convert the result into MP4\n",
        "!ffmpeg -y -loglevel info -i openpose.avi output.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gDwsrhqlgIW"
      },
      "source": [
        "#@title ###*Детектируем позы футболистов на видео с увеличенным разрешением ESRGAN* { display-mode: \"form\" }\n",
        "!rm openpose.avi\n",
        "!cd openpose && ./build/examples/openpose/openpose.bin --video /content/upscaled_video.mp4 --write_json ./output/ --display 0  --write_video ../openpose.avi\n",
        "# convert the result into MP4\n",
        "!ffmpeg -y -loglevel info -i openpose.avi output2.mp4"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}